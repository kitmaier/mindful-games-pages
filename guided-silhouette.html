<!DOCTYPE html>
<html>
	<head>
		<title>Guided Body Scan Meditation</title>
		<meta name="description" content="Relax with a meditation game that will guide you through gaining a deeper awareness of your body.">
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
	</head>
	<body id='body'>
		<p><a href="index.html">Return to games index</a></p>
		<h1>Guided Body Scan Meditation</h1>
		<p>Direct your attention to sensations <br/>in the lightened part of the body below, <br/>looking at it as though it was in a mirror.</p>
		<p><button id="toggleActive" type="button" onclick="toggleActive()">Push to Start</button></p>
		<svg id="svgId" height="200" width="200" onClick="clickPixel(event)">
			Sorry, your browser does not support inline SVG.
		</svg> 
		<p id="bodypart"></p>
		<button id="toggleAudio" type="button" onclick="toggleAudio()">Audio Disabled</button>
		<button id="toggleAudioCapture" type="button" onclick="toggleAudioCapture()">Audio Capture Disabled</button>
		<button id="toggleTextConversion" type="button" onclick="toggleTextConversion()">Speech-to-Text Disabled</button>
		<p>To customize what is included in the scan, <br/>you can modify the below options.</p>
		<p id='options'></p>
		<p id='audio'></p>
		<script type="text/javascript" src="generic-logging-client-function.js"></script>
		<script src="NoSleep.min.js"></script>
		<script src="web_audio_recorder_js/WebAudioRecorder.js"></script>
		<script>
			// TODO: do something about these two errors: 
			//    guidedsilhouette.html:1 Access to XMLHttpRequest at 'https://yzb3dh02l8.execute-api.us-west-2.amazonaws.com/default/myFunction-3?game=guidedsilhouette&ip=104.1.54.246&session=0.0664505495303993&timestamp=1574037009780&sequence=1&data=%5B%22startGame%22%5D' from origin 'null' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.
			//    guidedsilhouette.html:480 Cross-Origin Read Blocking (CORB) blocked cross-origin response https://yzb3dh02l8.execute-api.us-west-2.amazonaws.com/default/myFunction-3?game=guidedsilhouette&ip=104.1.54.246&session=0.0664505495303993&timestamp=1574037009780&sequence=1&data=%5B%22startGame%22%5D with MIME type application/json. See https://www.chromestatus.com/feature/5629709824032768 for more details.
			// TODO: try auto-pushing the button to enable recording with an artifical button press https://stackoverflow.com/questions/21012580/is-it-possible-to-write-data-to-file-using-only-javascript
			// TODO: provide download link for audio recordings https://stackoverflow.com/questions/21012580/is-it-possible-to-write-data-to-file-using-only-javascript
			// TODO: search converted speech-to-text data for a keyword like "Stop" to indicate the chosen end of recording, so the user does not have to push a button
			// TODO: trim out silence or non-speech sounds from recording before submitting for speech-to-text conversion
			/** START GAME STATE SECTION **/
				// Sleep state handling
					var noSleep = new NoSleep()
					var sleepStatus = "sleepAllowed"
					function setSleepStatus(newSleepStatus) {
						if(newSleepStatus=="sleepAllowed") {
							noSleep.disable()
							sleepStatus = "sleepAllowed"
						} else if(newSleepStatus=="wakeLocked") {
							noSleep.enable()
							sleepStatus = "wakeLocked"
						}
					}
				// State transition handling
					var state = "inactive"
					function toggleActive() {
						if(state=="inactive"||state=="paused") {
							changeStateTo("active")
						} else if(state=="active") {
							changeStateTo("inactive")
						}
					}
					function stopGame() {
						changeStateTo("inactive")
					}
					function changeStateTo(newState) {
						// TODO: add locking/queueing to handle concurrent events (or maybe is not needed??? https://developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop)
						clearTimeout(timerId)
						darkenSilhouette()
						stopAudio()
						if(newState=="active") {
							state = "active"
							logEvent("guidedsilhouette",["event=startGame"])
							setSleepStatus("wakeLocked")
							document.getElementById("toggleActive").textContent = "Push to Stop"
							stopAudioCapture()
							stepsUntilPause = Math.floor(Math.random()*20)+3
							brightenOnRandomSchedule()
						} else if(newState=="inactive") {
							state = "inactive"
							logEvent("guidedsilhouette",["event=stopGame"])
							setSleepStatus("sleepAllowed")
							document.getElementById("toggleActive").textContent = "Push to Start"
							stopAudioCapture()
							displayBodyPartName("Stopped")
						} else if(newState=="paused") {
							state = "inactive"
							logEvent("guidedsilhouette",["event=pauseGame"])
							setSleepStatus("wakeLocked")
							document.getElementById("toggleActive").textContent = "Push to Unpause"
							startAudioCapture()
							displayBodyPartName("Unpause")
							timerId = setTimeout(stopGame, 2*60*1000)
						}
					}
				// Random event handling
					var timerId = null
					var stepsUntilPause = 0
					function brightenOnRandomSchedule() {
						if(stepsUntilPause>0) {
							stepsUntilPause -= 1
							// TODO: allow timing parameters to be set by user
							brightenRandomBodyPart()
							var timeoutValue = 7+Math.floor(Math.random()*25)
							timerId = setTimeout(brightenOnRandomSchedule, timeoutValue*1000)
						} else {
							changeStateTo("paused")
						}
						// TODO: prevent the same event from happening twice in a row
						// TODO: break in with other random events sometimes, such as instructions, questions, and reminders
					}
				// Disabled
					function clickPixel(event) {
						// TODO: re-implement this method if it is needed, or remove stub
					}
			/** END GAME STATE SECTION **/
			/** START AUDIO SECTION **/
				// TODO: try using build in HTML5 Speech Synthesis API (https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis)
				// Initialize static data
					var audioFiles = {}
					setupAudio()
					function setupAudio() {
						audioFiles["Left Hand"] = new Audio("audio/left-hand.mp3")
						audioFiles["Right Hand"] = new Audio("audio/right-hand.mp3")
						audioFiles["Left Arm"] = new Audio("audio/left-arm.mp3")
						audioFiles["Right Arm"] = new Audio("audio/right-arm.mp3")
						audioFiles["Head & Face"] = new Audio("audio/head-and-face.mp3")
						audioFiles["Neck & Shoulders"] = new Audio("audio/neck-and-shoulders.mp3")
						audioFiles["Chest & Back"] = new Audio("audio/chest-and-back.mp3")
						audioFiles["Pelvis & Belly"] = new Audio("audio/pelvis-and-belly.mp3")
						audioFiles["Left Leg"] = new Audio("audio/left-leg.mp3")
						audioFiles["Right Leg"] = new Audio("audio/right-leg.mp3")
						audioFiles["Left Foot"] = new Audio("audio/left-foot.mp3")
						audioFiles["Right Foot"] = new Audio("audio/right-foot.mp3")
						audioFiles["Click Somewhere"] = new Audio("audio/click-somewhere.mp3")
						audioFiles["Unpause"] = new Audio("audio/unpause.mp3")
						audioFiles["Chin"] = new Audio("audio/chin.mp3")
						audioFiles["Forehead"] = new Audio("audio/forehead.mp3")
						audioFiles["Jaw Muscles"] = new Audio("audio/jaw-muscles.mp3")
						audioFiles["Left Cheek"] = new Audio("audio/left-cheek.mp3")
						audioFiles["Right Cheek"] = new Audio("audio/right-cheek.mp3")
						audioFiles["Left Eye"] = new Audio("audio/left-eye.mp3")
						audioFiles["Right Eye"] = new Audio("audio/right-eye.mp3")
						audioFiles["Lips"] = new Audio("audio/lips.mp3")
						audioFiles["Nose"] = new Audio("audio/nose.mp3")
						audioFiles["Teeth & Gums"] = new Audio("audio/teeth-gums.mp3")
						audioFiles["Throat & Sinuses"] = new Audio("audio/throat-sinuses.mp3")
						audioFiles["Tongue & Mouth"] = new Audio("audio/tongue-roof.mp3")
					}
				// Manage events and states
					var audioStatus = "disabled"
					var activeRecording = null
					function toggleAudio() {
						if(audioStatus=="disabled") {
							audioStatus = "enabled"
							logEvent("guidedsilhouette",["event=enableAudio"])
							document.getElementById("toggleAudio").textContent = "Audio Enabled"
						} else {
							audioStatus = "disabled"
							logEvent("guidedsilhouette",["event=disableAudio"])
							document.getElementById("toggleAudio").textContent = "Audio Disabled"
							stopAudio()
						}
					}
					function playAudio(bodyPart) {
						// This must be preceded by a gesture (button press)
						if(audioStatus=="enabled") {
							stopAudio()
							var audioFile = audioFiles[bodyPart]
							audioFile.play()
							activeRecording = audioFile
						}
					}
					function stopAudio() {
						if(activeRecording!=null) {
							activeRecording.pause();
							activeRecording.currentTime = 0;
							activeRecording = null
						}
					}
			/** END AUDIO SECTION **/
			/** START AUDIO CAPTURE SECTION **/
				// Using this library for audio capture https://www.npmjs.com/package/web-audio-recorder-js
				// Must run chrome with this flag (--allow-file-access-from-files) to test locally
				// TODO: expand speech-to-text capability https://codeburst.io/html5-speech-recognition-api-670846a50e92)
				// initialize audio capture
					var recorder = null;
					var audioContext = null;
					var audioDestination = null;
					var audioCaptureState = "uninitialized"
					function initializeAudioCapture() {
						// This must be preceded by a gesture (button press)
						audioCaptureState = "disabled";
						audioContext = new AudioContext();
						if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
							navigator.mediaDevices.getUserMedia({audio:true}).then(
								function(stream) {
									start_microphone(stream);
								},
								function(error){
									alert('Error capturing audio.');
								}
							)
						} else {
							alert('navigator.mediaDevices.getUserMedia not supported in this browser.');
						}
					}
					function start_microphone(stream) {
						var microphone_stream = audioContext.createMediaStreamSource(stream);
						var gain_node = audioContext.createGain();
						//gain_node.gain.value = 10;
						microphone_stream.connect(gain_node);
						audioDestination = gain_node;
					}
				// enable/disable audio capture
					function toggleAudioCapture() {
						if(audioCaptureState=="uninitialized") {
							initializeAudioCapture();
						}
						if(audioCaptureState=="disabled") {
							audioCaptureState = "enabled";
							document.getElementById("toggleAudioCapture").textContent = "Audio Capture Enabled"
						} else if(audioCaptureState=="enabled") {
							audioCaptureState = "disabled";
							document.getElementById("toggleAudioCapture").textContent = "Audio Capture Disabled"
						} else if(audioCaptureState=="recording") {
							stopAudioCapture();
							audioCaptureState = "disabled";
							document.getElementById("toggleAudioCapture").textContent = "Audio Capture Disabled"
						}
					}
				// functions to start and stop audio capture
					// TODO: should i keep the same variables or recreate them each time? is there any risk of a memory leak or other buildup over time?
					// TODO: should i delay the start of recording until after the command has finished?
					// TODO: give explicit instruction to user to speak during audio capture
					// TODO: store recording into database as clob and provide way to retrieve/play
					// TODO: process recording through speech-to-text and store text in database for later analysis
					function startAudioCapture() {
						if(audioCaptureState=="enabled") {
							audioCaptureState = "recording"
							// TODO: notify user while recording is active
							recorder = new WebAudioRecorder(audioDestination, {
								workerDir: "web_audio_recorder_js/", // must end with slash
								encoding: "wav",
								numChannels:1, //2 is the default, mp3 encoding supports only 2
								onEncoderLoading: function(recorder, encoding) {
									// show "loading encoder..." display
									console.log("Loading "+encoding+" encoder...");
								},
								onEncoderLoaded: function(recorder, encoding) {
									// hide "loading encoder..." display
									console.log(encoding+" encoder loaded");
								}
							});
							recorder.setOptions({
								timeLimit:120,
								encodeAfterRecord:true,
								ogg: {quality: 0.5},
								mp3: {bitRate: 160}
							});
							recorder.onComplete = function(recorder, blob) { 
								var recordingDate = new Date();
								var recordingTime = recordingDate.getTime();
								var recordingId = "recording_"+recordingTime;
								var audioTag = document.getElementById("audio")
								var sound = document.createElement('audio');
								sound.controls = 'controls';
								var soundUrl = URL.createObjectURL(blob);
								sound.src = soundUrl;
								var paragraph = document.createElement("p");
								var text = document.createTextNode("Recording ("+(new Date())+"): ");
								audioTag.appendChild(paragraph);
								var anchor = document.createElement("a");
								anchor.href = soundUrl;
								anchor.download = recordingId;
								paragraph.appendChild(anchor);
								var text = document.createTextNode("Recording ("+recordingDate+"): ");
								anchor.appendChild(text);
								paragraph.appendChild(sound);
								paragraph.id = recordingId;
								blobToTranscript(blob, recordingId);
							}
							recorder.startRecording();
						}
					}
					function stopAudioCapture() {
						if(audioCaptureState=="recording") {
							audioCaptureState = "enabled"
							recorder.finishRecording()
						}
					}
			/** END AUDIO CAPTURE SECTION **/
			/** START SPEECH TO TEXT SECTION **/
				// initialize state
					var textConversionState = "disabled"
				// enable/disable speech-to-text conversion
					function toggleTextConversion() {
						if(textConversionState=="disabled") {
							textConversionState = "enabled"
							document.getElementById("toggleTextConversion").textContent = "Speech-to-Text Enabled"
						} else if(textConversionState=="enabled") {
							textConversionState = "disabled"
							document.getElementById("toggleTextConversion").textContent = "Speech-to-Text Disabled"
						}
					}
				// conversion functions
					function blobToTranscript(blob, recordingId) {
						if(textConversionState=="enabled") {
							blobToBase64(blob, convertSpeechToText, recordingId)
						}
					}
					function blobToBase64(blob, convertSpeechToText, recordingId) {
						var reader = new FileReader();
						reader.onload = function() {
							var dataUrl = reader.result;
							var base64 = dataUrl.split(',')[1];
							convertSpeechToText(base64, recordingId);
						};
						reader.readAsDataURL(blob);
					};
					function convertSpeechToText(base64, recordingId) {
						var message = 	{
											"config": {
												"languageCode": "en-US",
												"enableWordTimeOffsets": false,
												"enableAutomaticPunctuation": true,
												"model": "phone_call",
												"useEnhanced": true,
												"audio_channel_count": 1
											},
											"audio": {
												"content": base64
											}
										};
						var xmlhttp = new XMLHttpRequest();
						// TODO: replace this publicly visible API key with a more secure solution
						// TODO: figure out how to charge usage to the client's Google account instead of my own
						var theUrl = "https://speech.googleapis.com/v1/speech:recognize?key=AIzaSyBgsX5jnnYjDPwtSuSlLrRsW50x3tFdmCA";
						xmlhttp.onreadystatechange = function() {
							if (xmlhttp.readyState === 4) {
								console.log(xmlhttp.response)
								// TODO: with my current subscription this will only work for up to one minute of audio (could notify the user, provide hard constraints on the recording, try to split recording up into pieces, push the recording to google cloud, try out the continuous transcription api, bump up the limit, provide meaningful error messages back to user)
								var results = JSON.parse(xmlhttp.response)["results"]
								var transcript = "Transcript:"
								for(var k=0; k<results.length; k++) {
									transcript += " " + results[k]["alternatives"][0]["transcript"]
								}
								displayTranscript(transcript, recordingId)
							}
						}
						xmlhttp.open("POST", theUrl);
						xmlhttp.setRequestHeader("Content-Type", "application/json");
						xmlhttp.send(JSON.stringify(message));
					}
					function displayTranscript(transcript, recordingId) {
						var paragraph = document.getElementById(recordingId)
						var text = document.createTextNode(transcript);
						paragraph.appendChild(text);
						// TODO: try to relate this event back to the pause/stop events that gave rise to it
						logEvent("guidedsilhouette",["event=speechToText","eventId="+recordingId,"eventText="+transcript])
					}
			/** END SPEECH TO TEXT SECTION **/
			/** START GRAPHICS SECTION **/
				// Initialize static data
					// TODO: make this graphic more detailed and better-looking
					// TODO: create more detailed body parts, including front/back (eg chest vs back)
					// TODO: create detailed graphics for specific body parts (eg hand)
					var pixels = [[8,2],[9,2],[10,2],
								  [8,3],[9,3],[10,3],
								  [8,4],[9,4],[10,4],
										[9,5],
							[7,6],[8,6],[9,6],[10,6],[11,6],
					  [6,7],[7,7],[8,7],[9,7],[10,7],[11,7],[12,7],
				[5,8],[6,8],[7,8],[8,8],[9,8],[10,8],[11,8],[12,8],[13,8],
		  [4,9],[5,9],      [7,9],[8,9],[9,9],[10,9],[11,9],       [13,9],[14,9],
	[3,10],[4,10],        [7,10],[8,10],[9,10],[10,10],[11,10],          [14,10],[15,10],
	[3,11],[4,11],        [7,11],[8,11],[9,11],[10,11],[11,11],          [14,11],[15,11],
						  [7,12],[8,12],       [10,12],[11,12],
						  [7,13],[8,13],       [10,13],[11,13],
						  [7,14],[8,14],       [10,14],[11,14],
						  [7,15],[8,15],       [10,15],[11,15],
				   [6,16],[7,16],[8,16],       [10,16],[11,16],[12,16],
				   [6,17],[7,17],[8,17],       [10,17],[11,17],[12,17]]
					var pixelsLookup = {
						"Left Hand":[[3,10],[4,10],[3,11],[4,11]],
						"Right Hand":[[14,10],[15,10],[14,11],[15,11]],
						"Left Arm":[[4,9],[5,9],[5,8],[6,8],[6,7]],
						"Right Arm":[[12,7],[12,8],[13,8],[13,9],[14,9]],
						"Head & Face":[[8,2],[9,2],[10,2],[8,3],[9,3],[10,3],[8,4],[9,4],[10,4]],
						"Neck & Shoulders":[[9,5],[7,6],[8,6],[9,6],[10,6],[11,6]],
						"Chest & Back":[[7,7],[8,7],[9,7],[10,7],[11,7],[7,8],[8,8],[9,8],[10,8],[11,8],[7,9],[8,9],[9,9],[10,9],[11,9]],
						"Pelvis & Belly":[[7,10],[8,10],[9,10],[10,10],[11,10],[7,11],[8,11],[9,11],[10,11],[11,11]],
						"Left Leg":[[7,12],[8,12],[7,13],[8,13],[7,14],[8,14],[7,15],[8,15]],
						"Right Leg":[[10,12],[11,12],[10,13],[11,13],[10,14],[11,14],[10,15],[11,15]],
						"Left Foot":[[6,16],[7,16],[8,16],[6,17],[7,17],[8,17]],
						"Right Foot":[[10,16],[11,16],[12,16],[10,17],[11,17],[12,17]],
						"Chin":[], // TODO: create pictures for these new body parts
						"Forehead":[],
						"Jaw Muscles":[],
						"Left Cheek":[],
						"Right Cheek":[],
						"Left Eye":[],
						"Right Eye":[],
						"Lips":[],
						"Nose":[],
						"Teeth & Gums":[],
						"Throat & Sinuses":[],
						"Tongue & Mouth":[]
					}
					var pixelsReverseLookup = {}
					createPixelsReverseLookup()
					function createPixelsReverseLookup() {
						for(var bodyPart in pixelsLookup) {
							var pixelList = pixelsLookup[bodyPart]
							for(var k=0; k<pixelList.length; k++) {
								var pixelLoc = pixelList[k]
								pixelsReverseLookup[pixelLoc] = bodyPart
							}
						}
					}
				// Initialize graphic elements
					createPixels()
					function createPixels() {
						var svg = document.getElementById("svgId")
						for(var x=0; x<20; x++) {
							for(var y=0; y<20; y++) {
								var rect = document.createElementNS("http://www.w3.org/2000/svg","rect")
								rect.setAttribute("id","pixel_"+x+"_"+y)
								rect.setAttribute("x",x+"0")
								rect.setAttribute("y",y+"0")
								rect.setAttribute("width","10")
								rect.setAttribute("height","10")
								rect.setAttribute("style","fill:white;stroke:white;stroke-width:1")
								svg.appendChild(rect)
							}
						}
					}
					darkenSilhouette()
					function darkenSilhouette() {
						setColorOnPixels("black",pixels)
					}
					function setColorOnPixels(color,pixels) {
						try {
							for(var k=0; k<pixels.length; k++) {
								document.getElementById("pixel_"+pixels[k][0]+"_"+pixels[k][1]).setAttribute("style","fill:"+color+";stroke:"+color+";stroke-width:1")
							}
						} catch(error) {
							alert(error.message)
						}
					}
					// TODO: combine all the bodyparts lists into one data structure
					// TODO: move these lists to the static data section
					var bodyPartsList = ["Head & Face","Neck & Shoulders","Chest & Back","Left Arm",
						"Right Arm","Left Hand","Right Hand","Pelvis & Belly",
						"Left Leg","Right Leg","Left Foot","Right Foot"]
					var facePartsList = ["Forehead","Jaw Muscles","Left Eye","Right Eye",
						"Left Cheek","Right Cheek","Nose","Lips","Chin",
						"Throat & Sinuses","Tongue & Mouth","Teeth & Gums"]
					// TODO: make these functions more generic and loop over list of body regions
					createOptions()
					function createOptions() {
						var paragraph = document.getElementById("options")
						var bodySpan = document.createElement("span")
						bodySpan.id = "bodyHeader"
						bodySpan.innerHTML = "&nbsp;<input type='checkbox' id='bodyHeaderCheckbox' onClick='handleCheckboxEvent(event)'> Category: Body &nbsp;[Expand <input type='checkbox' id='bodyExpandCheckbox' onClick='handleCheckboxEvent(event)'>]<br/>"
						paragraph.appendChild(bodySpan)
						document.getElementById("bodyHeaderCheckbox").checked = true
						for(var k=0; k<bodyPartsList.length; k++) {
							var bodyPart = bodyPartsList[k]
							var bodyPartSpan = document.createElement("span")
							bodyPartSpan.id = bodyPart+" Span"
							bodyPartSpan.innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<input type='checkbox' id='"+bodyPart+" Checkbox' onClick='handleCheckboxEvent(event)'> "+bodyPart+"<br>"
							bodyPartSpan.style.display = "none"
							paragraph.appendChild(bodyPartSpan)
							document.getElementById(bodyPart+" Checkbox").checked = true
						}
						var faceSpan = document.createElement("span")
						faceSpan.id = "faceHeader"
						faceSpan.innerHTML = "&nbsp;<input type='checkbox' id='faceHeaderCheckbox' onClick='handleCheckboxEvent(event)'> Category: Face &nbsp;[Expand <input type='checkbox' id='faceExpandCheckbox' onClick='handleCheckboxEvent(event)'>]<br/>"
						paragraph.appendChild(faceSpan)
						for(var k=0; k<facePartsList.length; k++) {
							var facePart = facePartsList[k]
							var facePartSpan = document.createElement("span")
							facePartSpan.id = facePart+" Span"
							facePartSpan.innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<input type='checkbox' id='"+facePart+" Checkbox' onClick='handleCheckboxEvent(event)'> "+facePart+"<br>"
							facePartSpan.style.display = "none"
							paragraph.appendChild(facePartSpan)
						}
					}
					function handleCheckboxEvent(event) {
						var targetId = event.target.id
						if(targetId=="bodyHeaderCheckbox") {
							var checkboxValue = document.getElementById(targetId).checked
							for(var k=0; k<bodyPartsList.length; k++) {
								var bodyPartCheckbox = document.getElementById(bodyPartsList[k]+" Checkbox")
								bodyPartCheckbox.checked = checkboxValue
							}
						}
						if(targetId=="bodyExpandCheckbox") {
							var checkboxValue = document.getElementById(targetId).checked
							for(var k=0; k<bodyPartsList.length; k++) {
								var bodyPartSpan = document.getElementById(bodyPartsList[k]+" Span")
								if(checkboxValue) {
									bodyPartSpan.style.display = "block"
								} else {
									bodyPartSpan.style.display = "none"
								}
							}
						}
						if(targetId=="faceHeaderCheckbox") {
							var checkboxValue = document.getElementById(targetId).checked
							for(var k=0; k<facePartsList.length; k++) {
								var facePartCheckbox = document.getElementById(facePartsList[k]+" Checkbox")
								facePartCheckbox.checked = checkboxValue
							}
						}
						if(targetId=="faceExpandCheckbox") {
							var checkboxValue = document.getElementById(targetId).checked
							for(var k=0; k<facePartsList.length; k++) {
								var facePartSpan = document.getElementById(facePartsList[k]+" Span")
								if(checkboxValue) {
									facePartSpan.style.display = "block"
								} else {
									facePartSpan.style.display = "none"
								}
							}
						}
					}
					function isChecked(bodyPart) {
						return document.getElementById(bodyPart+" Checkbox").checked
					}
				// Display active graphics
					function brightenBodyPart(bodyPart) {
						setColorOnPixels("yellow",pixelsLookup[bodyPart])
						displayBodyPartName(bodyPart)
						logEvent("guidedsilhouette",["event=brightenBodyPart","bodyPart="+bodyPart])
					}
					function brightenRandomBodyPart() {
						darkenSilhouette()
						// TODO: implement optional body part clustering, where consecutive body parts will tend to be in the same region
						var bodyParts = []
						for(var k=0; k<bodyPartsList.length; k++) {
							var bodyPart = bodyPartsList[k]
							if(isChecked(bodyPart)) {
								bodyParts.push(bodyPart)
							}
						}
						for(var k=0; k<facePartsList.length; k++) {
							var facePart = facePartsList[k]
							if(isChecked(facePart)) {
								bodyParts.push(facePart)
							}
						}
						// TODO: how to handle if the selection list is empty?
						if(bodyParts.length==0) {
							bodyParts.push("Head & Face")
						}
						var index = Math.floor(Math.random()*bodyParts.length)
						brightenBodyPart(bodyParts[index])
					}
					function displayBodyPartName(bodyPart) {
						if(bodyPart=="Click Somewhere") {
							document.getElementById("bodypart").textContent = "Click somewhere on the body"
							logEvent("guidedsilhouette",["event=clickSomewhere"])
						} else if(bodyPart=="Unpause") {
							document.getElementById("bodypart").textContent = "The game is paused"
						} else if(bodyPart=="Stopped") {
							document.getElementById("bodypart").textContent = "The game is stopped"
							return
						} else {
							document.getElementById("bodypart").textContent = "Focus on your "+bodyPart
						}
						playAudio(bodyPart)
					}
			/** END GRAPHICS SECTION **/
		</script>
	</body>
</html>